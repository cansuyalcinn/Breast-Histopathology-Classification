{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.Feature_extraction/AIA",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW8VOlOZ21xs",
        "outputId": "383dee3f-d9ce-4783-a22b-d5887b5220d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mouting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "LxY4UUJOAY9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Pyradiomics\n",
        "!pip install pyradiomics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSAdK_hl9DCY",
        "outputId": "b1c8b739-475a-474a-c6db-3871235feb10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyradiomics in /usr/local/lib/python3.7/dist-packages (3.0.1)\n",
            "Requirement already satisfied: SimpleITK>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from pyradiomics) (2.1.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pyradiomics) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyradiomics) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pyradiomics) (1.15.0)\n",
            "Requirement already satisfied: pykwalify>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pyradiomics) (1.8.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from pykwalify>=1.6.0->pyradiomics) (0.6.2)\n",
            "Requirement already satisfied: ruamel.yaml>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from pykwalify>=1.6.0->pyradiomics) (0.17.21)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from pykwalify>=1.6.0->pyradiomics) (2.8.2)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.16.0->pykwalify>=1.6.0->pyradiomics) (0.2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import skimage\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "#Local binary pattern\n",
        "from skimage.feature import local_binary_pattern\n",
        "\n",
        "#GLCM\n",
        "from radiomics.glcm import RadiomicsGLCM\n",
        "from radiomics import featureextractor  # This module is used for interaction with pyradiomics\n",
        "import SimpleITK as sitk\n",
        "import six\n",
        "import pickle"
      ],
      "metadata": {
        "id": "EFgBeAMC3Bbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Global dictionaries\n",
        "mag_dict = {0:'40',1:'100',2:'200',3:'400'}\n",
        "tt_dict = {0:'train',1:'test'}"
      ],
      "metadata": {
        "id": "0ApGl2f93LMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "O22qhGx382Fc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LBP"
      ],
      "metadata": {
        "id": "zHrT_okG_rXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_LBP(path_folder):\n",
        "  \"\"\"\n",
        "  Compute the rotation invariant uniform (frequent) LBP feature from all images in a folder.\n",
        "  Returns the feature matrix mxn (m patient, n features)\n",
        "  :param path_folder: list of paths of all images in given folder\n",
        "  :return: feature matrix mxn\n",
        "  \"\"\"\n",
        "  lbp_feature_vector=[]\n",
        "  for path in tqdm(path_folder): \n",
        "      im = cv.cvtColor(cv.imread(path),cv.COLOR_BGR2GRAY);\n",
        "      im_lbp = local_binary_pattern(im,P=8,R=1,method='uniform')\n",
        "      hist = np.histogram(im_lbp.ravel())\n",
        "      feature_array=np.ndarray.tolist(hist[0])\n",
        "      #Add endpoint. Benign=0, Malignant=1.\n",
        "      feature_array.append(int(path.find('_M_')!=-1))\n",
        "      #Add patient ID\n",
        "      feature_array.insert(0,path.rsplit('/', 1)[1].split('-', 3)[2])\n",
        "      #Save feature array in list\n",
        "      lbp_feature_vector.append(feature_array)\n",
        "  return lbp_feature_vector"
      ],
      "metadata": {
        "id": "3MCmZJbh3Xub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GLCM"
      ],
      "metadata": {
        "id": "1APmyQbVAJK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### GLCM\n",
        "####\n",
        "def extractor_setting(feature_names):\n",
        "  \"\"\"\n",
        "  Settings of the feature extraction\n",
        "  \n",
        "  :param feature_names: list of the names of the features to be extracted\n",
        "      e.g. features_names = ['JointEnergy', 'Contrast','Correlation']\n",
        "  :return: extractor with pre-defined settings and the # of features (length of feature_names)\n",
        "  \"\"\"\n",
        "\n",
        "  settings = {}\n",
        "  settings['binWidth'] = 1 #To ensure a 1 pixel width for the histogram onece the image has been requantized to 8 gray levels.\n",
        "  settings['correctMask'] = True #To ensure the mask and the image are in the same coordinates\n",
        "  # Instantiate the extractor\n",
        "  extractor = featureextractor.RadiomicsFeatureExtractor(**settings)\n",
        "  extractor.disableAllFeatures()\n",
        "  #extractor.enableFeatureClassByName('glcm') #Enable all GLCM features\n",
        "  extractor.enableFeaturesByName(glcm=feature_names)\n",
        "  num_features = len(feature_names)\n",
        "  print('Extraction parameters:\\n\\t', extractor.settings)\n",
        "  print('Enabled filters:\\n\\t', extractor.enabledImagetypes)\n",
        "  print('Enabled features:\\n\\t', extractor.enabledFeatures)\n",
        "  return extractor, num_features\n",
        "\n",
        "def GLCM_feature_im(img_path, extractor, num_features):\n",
        "  \"\"\"\n",
        "  Description: Extract GLCM features from an image. Requantization to 8 gray levels.\n",
        "\n",
        "  :param img_path: Path of image from which the features willbe obtain\n",
        "  :param extractor: Pyradiomics extractor defined in function extractor_settings\n",
        "  :param num_features: # of features given by function extractor_settings.\n",
        "  :return: feature vector\n",
        "  \"\"\"\n",
        "\n",
        "  #Read image\n",
        "  img = cv.cvtColor(cv.imread(img_path),cv.COLOR_BGR2GRAY)#Read and to grayscale\n",
        "  im = np.uint8(np.digitize(img, np.arange(0,256, 32))) - 1 #Normalize to 8 gray level\n",
        "  im_im = sitk.GetImageFromArray(im) #Pass to sitk objet\n",
        "  #mask\n",
        "  mask = np.ones(im.shape).astype(np.uint8) #Create maskwith same shape as image\n",
        "  mask[-1,-1]=0 #Hack to allow full image segmentation. Last value is set to 0 so it wont be counted in the GLCM computation\n",
        "  mask_im = sitk.GetImageFromArray(mask) #Pass to sitk object\n",
        "  #Extract\n",
        "  result = extractor.execute(im_im,mask_im) # Extract features\n",
        "  features = np.array(list(result.values())[-num_features:]) #save as array\n",
        "  return features\n",
        "\n",
        "def GLCM_for_folder(paths, f, tt, mag, num_features, extractor):\n",
        "  \"\"\"\n",
        "  Definition: Extract feature vector for all images in a folder, saved as a pickle numpy matrix\n",
        "\n",
        "  :param paths: paths of images\n",
        "  :param f: fold number-1\n",
        "  :param tt: train or test encoded\n",
        "  :param mag: magnification encoded using dictionary\n",
        "  :param num_features: Number of features ot be extracted. It defines the size of the feature matrix\n",
        "  :param extractor: Pyradiomics extractor with presettings\n",
        "  :return: NONE (Pickle file will be saved in drive)\n",
        "  \"\"\"\n",
        "\n",
        "  paths_folder = paths[f,tt,mag] #Paths of the first folder (There are 40)\n",
        "  n = len(paths_folder) #number of images (samples)\n",
        "  feature_matrix = np.zeros((n,num_features),dtype=np.float32) #Shape of feature matrix set\n",
        "\n",
        "  #Extraction of features\n",
        "  for i in tqdm(range(n)):\n",
        "    img_path = paths_folder[i] #Image from which features are extracted\n",
        "    ft_v = GLCM_feature_im(img_path, extractor, num_features) #Returns feature vector of m-dimension\n",
        "    feature_matrix[i,:] = ft_v\n",
        "  #Saving document\n",
        "  file_name = f'/content/drive/MyDrive/Ars_machinae_autodiscentis/Inceptum/fold{f+1}/{tt_dict[tt]}/GLCM_f{f+1}_{tt_dict[tt]}_{mag_dict[mag]}x_fv.p'\n",
        "  with open(file_name, 'wb') as handle:\n",
        "      pickle.dump(feature_matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "SY26Pi96-pe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PFTAS"
      ],
      "metadata": {
        "id": "SO0LUZ_uAAB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PFTAS(image_path):\n",
        "  #This function gives PFTAS per !IMAGE!\n",
        "  chs = cv.imread(image_path)\n",
        "  feature_vector = np.array([]) #Array with final 81 features\n",
        "  for i in range(3): #Three channels\n",
        "    ch = chs[:,:,i] #Obtain one channel image\n",
        "    ch_T,_ = cv.threshold(ch,0,255,type=cv.THRESH_BINARY + cv.THRESH_OTSU) #Otsu T\n",
        "    mu = ((ch>ch_T)*ch).sum()/np.sum(ch>ch_T) #Mean value for pixels above Otsu T\n",
        "    std_ch = ch[ch>ch_T].std() #Std of pixels above threshold\n",
        "    \n",
        "    #Define windows for binarization\n",
        "    w1 = ((ch > (mu - std_ch))*(ch < (mu + std_ch)));\n",
        "    w2 = (ch > (mu - std_ch))\n",
        "    w3 = (ch > mu)\n",
        "    window = {0: w1, 1: w2, 2: w3, 3: ~w1, 4: ~w2, 5: ~w3} #Put all thresholding criteria together\n",
        "    \n",
        "    feature_vector_ch = np.array([]) #(This will contain the 27 features of the channel)*2 because of bitwise inversion\n",
        "    for w in window:\n",
        "      fv_w = feature_v_per_window(window[w])\n",
        "      feature_vector_ch = np.append(feature_vector_ch,fv_w) #Append the (27 features)*2\n",
        "    feature_vector = np.append(feature_vector,feature_vector_ch) #Append the (81 vectors)*2\n",
        "  return feature_vector\n",
        "\n",
        "def feature_v_per_window(window):\n",
        "  #Function used inside PFTAS. It computes the number of white neighbor in each window\n",
        "  thresh = window.astype(np.uint8)\n",
        "  ker = np.ones((3, 3))\n",
        "  ker[1,1]=10; #The value 10 is given to separate black and white central pixels\n",
        "  ch_conv = cv.filter2D(thresh,kernel=ker,ddepth=-1,borderType=cv.BORDER_REFLECT) #Convolution to count neighbors\n",
        "  values = np.histogram(ch_conv,bins=range(20))[0][-9:] #Last 9 values are the white pixels histgram values\n",
        "  feature_v = values/float(values.sum())\n",
        "  return feature_v\n",
        "\n",
        "def get_PFTAS(path_folder):\n",
        "  #This function give PFTAS list per !FOLDER!\n",
        "  PFTAS_feature_vector=[]\n",
        "  for path in tqdm(path_folder):\n",
        "      feature_array=np.ndarray.tolist(PFTAS(path))\n",
        "      #Add endpoint. Benign=0, Malignant=1.\n",
        "      feature_array.append(int(path.find('_M_')!=-1))\n",
        "      #Add patient ID\n",
        "      feature_array.insert(0,path.rsplit('/', 1)[1].split('-', 3)[2])\n",
        "      #Save feature array in list\n",
        "      PFTAS_feature_vector.append(feature_array)\n",
        "  return PFTAS_feature_vector"
      ],
      "metadata": {
        "id": "jA6Ou07j3ipZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gabor features"
      ],
      "metadata": {
        "id": "Srd21b0CAFjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creation of Gabor Filters\n",
        "def Gabor(path):\n",
        "   # Gabor filters are band pass filters, they allow certain frequencies and reject others.\n",
        "   #read the image for each path. \n",
        "   im = cv.cvtColor(cv.imread(path), cv.COLOR_BGR2GRAY)\n",
        "   ## reshape the image and put it in our feature vector as a first entity\n",
        "   img2 = im.reshape(-1)\n",
        "   df = pd.DataFrame()\n",
        "   df['1'] = img2\n",
        "   #Generate Gabor features\n",
        "   num = 2  #To count numbers up in order to give Gabor features a label in the data frame\n",
        "   kernels = []  #Create empty list to hold all kernels that we will generate in a loop\n",
        "   lamda = np.pi / 4\n",
        "   psi = 0\n",
        "   for theta in range(2):   #Define number of thetas. Here 4 theta values 0 and 1/4 . pi 1/2pi and 3pi/2 (all 4 directions)\n",
        "       theta = theta / 4. * np.pi\n",
        "       for sigma in (0.2, 0.4):  #Sigma with values \n",
        "            for gamma in (0.5, 0.8):   #Gamma values            \n",
        "              gabor_label = 'Gabor' + str(num)  #Label Gabor columns as Gabor1, Gabor2, etc.\n",
        "              ksize=9\n",
        "              kernel = cv.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, psi, ktype=cv.CV_32F)    \n",
        "              kernels.append(kernel)\n",
        "              #Now filter the image and add values to a new column \n",
        "              fimg = cv.filter2D(img2, cv.CV_8UC3, kernel) # convolution\n",
        "              filtered_img = fimg.reshape(-1)\n",
        "              df[gabor_label] = filtered_img  #Labels columns as Gabor1, Gabor2, etc.\n",
        "              #print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)\n",
        "              num += 1  #Increment for gabor column label               \n",
        "   return df"
      ],
      "metadata": {
        "id": "rmcrV-gq6JXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Add the patient ID and Label then save Gabor features \n",
        "def get_Gabor(path_fold):\n",
        "  features = pd.DataFrame()\n",
        "\n",
        "  for path in tqdm(path_fold):\n",
        "    # save the gabor filters\n",
        "    feature_df = Gabor(path)\n",
        "    ## Take mean, varience, skenwness, kurtosis and minimum for each filter\n",
        "    df1=feature_df.mean().to_frame().T\n",
        "    df2=feature_df.var().to_frame().T\n",
        "    df3=feature_df.skew().to_frame().T\n",
        "    df4=feature_df.kurtosis(axis=0).to_frame().T\n",
        "    df5=feature_df.min().to_frame().T\n",
        "\n",
        "    frames = [df1, df2, df3, df4, df5]\n",
        "    result = pd.concat(frames, axis=1, join='inner')\n",
        "\n",
        "    # add patient ids\n",
        "    result.insert(0, \"0\", path.rsplit('/', 1)[1].split('-', 3)[2])\n",
        "    # add end point\n",
        "    result[\"label\"]=int(path.find('_M_')!=-1)\n",
        "\n",
        "    features = pd.concat([features, result])\n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "6hQLDb206gk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving files as csv"
      ],
      "metadata": {
        "id": "PGStjnYe_2-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################\n",
        "## Returns the csv file for a given folder, train test, magnifications, and feature name (LBP)\n",
        "def get_file_fv(paths,feature_name,fold, train_test, magnification, get_feature_type):\n",
        "  mag_dictionary = {0:'40',1:'100',2:'200',3:'400'}\n",
        "  fv = get_feature_type(paths[fold,train_test,magnification])\n",
        "  train_df=pd.DataFrame(np.row_stack(fv))\n",
        "  train_df.to_csv(f'/content/drive/MyDrive/Ars_machinae_autodiscentis/Inceptum/fold{fold+1}/{tt_dict[train_test]}/{feature_name}_f{fold+1}_{tt_dict[train_test]}_{mag_dictionary[magnification]}x_fv.csv', sep='\\t')"
      ],
      "metadata": {
        "id": "pP75QKau_4yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction"
      ],
      "metadata": {
        "id": "g7NabdKN8s1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load images paths\n",
        "with open('/content/drive/MyDrive/Ars_machinae_autodiscentis/Inceptum/paths.p', 'rb') as handle:\n",
        "    paths = pickle.load(handle)"
      ],
      "metadata": {
        "id": "dkI1nAhi3muc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extraction of LBP pattern for all folds, train-test and magnifications\n",
        "for fold in range(5):\n",
        "   for tt in range(2):\n",
        "     for mag in range(4):\n",
        "       get_file_fv(paths=paths, feature_name = 'lbp', fold=fold, train_test=tt, magnification=mag, get_feature_type=get_LBP)"
      ],
      "metadata": {
        "id": "9_ejFHV54HAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extraction of PFTAS pattern for all folds, train-test and magnifications\n",
        "for fold in range(5):\n",
        "   for tt in range(2):\n",
        "     for mag in range(4):\n",
        "       get_file_fv(paths=paths, feature_name = 'PFTAS', fold=fold, train_test=tt, magnification=mag, get_feature_type=get_PFTAS)"
      ],
      "metadata": {
        "id": "dDdMCuAX4vn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extraction of Gabor filters\n",
        "for fold in range(5):\n",
        "   for tt in range(2):\n",
        "     for mag in range(4):\n",
        "       get_file_fv(paths=paths, feature_name = 'Gabor', fold=fold, train_test=tt, magnification=mag , get_feature_type=get_Gabor)"
      ],
      "metadata": {
        "id": "ft_0J5qn6gsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GLCM extraction\n",
        "#Extractor settings and nanme of features to extract\n",
        "features_names = ['JointEnergy', 'Contrast','Correlation', 'SumSquares','Idm','SumAverage', 'ClusterTendency','SumEntropy','JointEntropy','DifferenceVariance','DifferenceEntropy','Imc1','Imc2'] #Name of features to extract\n",
        "extractor, num_features = extractor_setting(features_names) #Return extractor and number of features\n",
        "\n",
        "for fold in range(5):\n",
        "  for tt in range(2):\n",
        "    for mag in range(4):\n",
        "      GLCM_for_folder(paths=paths,f=fold, tt=tt, mag=mag, num_features=num_features, extractor=extractor) #Create and save feature matrices"
      ],
      "metadata": {
        "id": "sIR-S0GQDU1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}